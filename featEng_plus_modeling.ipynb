{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f6ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f24bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temps_dc = pd.read_csv('Data/full_temps_dc.csv')\n",
    "full_temps_dc['tavg'] = (full_temps_dc['tmin'] + full_temps_dc['tmax']) / 2\n",
    "full_temps_dc['date'] = pd.to_datetime(full_temps_dc['date'])\n",
    "\n",
    "temps_2026_dc = pd.read_csv(\"Data/dc_Temps_2026.csv\")\n",
    "temps_2026_dc['date'] = pd.to_datetime(temps_2026_dc['date'])\n",
    "temps_2026_dc['tavg'] = (temps_2026_dc['tmin'] + temps_2026_dc['tmax']) / 2\n",
    "temps_2026_dc['year'] = 2026\n",
    "temps_2026_dc['doy'] = temps_2026_dc['date'].dt.dayofyear\n",
    "\n",
    "cherry_dc = pd.read_csv(\"Q_blooms_dc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e87c5",
   "metadata": {},
   "source": [
    "## Creating Chill and GDD Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c3b09",
   "metadata": {},
   "source": [
    "Chill hours is defined as total hours per day where temperature < 7.2°C using daily min/max temperatures and a triangular approximation.\n",
    "\n",
    "Growing Degree Days (GDD) are a cumulative total of average temperatures being over the 4°C threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58ed84",
   "metadata": {},
   "source": [
    "#### Chill Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d889f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chill_hours(df, base_temp=7.2):\n",
    "    df = df.copy()\n",
    "    df['is_chill'] = df['tavg'] < base_temp\n",
    "    \n",
    "    chill = (\n",
    "        df.groupby(df['date'].dt.year)['is_chill']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={'date': 'year', 'is_chill': 'chill_hours'})\n",
    "    )\n",
    "    \n",
    "    chill.columns = ['year', 'chill_hours']\n",
    "    return chill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9650a7",
   "metadata": {},
   "source": [
    "#### Cumulative GDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3281636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cumulative_gdd(df, base_temp=4.4):\n",
    "    df = df.copy()\n",
    "    df['gdd'] = np.maximum(df['tavg'] - base_temp, 0)\n",
    "    \n",
    "    gdd = (\n",
    "        df.groupby(df['date'].dt.year)['gdd']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    gdd.columns = ['year', 'cumulative_gdd']\n",
    "    return gdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31247b",
   "metadata": {},
   "source": [
    "#### Threshold GDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7432d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_gdd(df, chill_df, chill_threshold=800, base_temp=4.4):\n",
    "    df = df.copy()\n",
    "    df['gdd'] = np.maximum(df['tavg'] - base_temp, 0)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    merged = df.merge(chill_df, on='year')\n",
    "    \n",
    "    threshold_results = []\n",
    "    \n",
    "    for year in merged['year'].unique():\n",
    "        year_data = merged[merged['year'] == year]\n",
    "        \n",
    "        if year_data['chill_hours'].iloc[0] >= chill_threshold:\n",
    "            gdd_total = year_data['gdd'].sum()\n",
    "        else:\n",
    "            gdd_total = 0\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'year': year,\n",
    "            'threshold_gdd': gdd_total\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(threshold_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddb722",
   "metadata": {},
   "source": [
    "### Severe Frost Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e3c57",
   "metadata": {},
   "source": [
    "Binary shock variable for temperatures under -4.4°C or 24°F, which can damage up to 90% of explosed blossoms affected by such low temperatures. [Source](\n",
    "https://www.nps.gov/nama/learn/news/cherry-blossom-update-cold-temperatures-causing-damage-to-advanced-stage-blossoms.htm#:~:text=Cherry%20blossoms%20start%20to%20sustain,exposed%20blossoms%20can%20be%20affected.\n",
    ")\n",
    "\n",
    " Since we are concerned about the effect of already exposed blossoms, this feature only tracks low temperatures after Febuary 15th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ffca755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_severe_frost(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    frost_list = []\n",
    "    \n",
    "    for year in df['year'].unique():\n",
    "        year_data = df[\n",
    "            (df['year'] == year) &\n",
    "            (df['date'] >= pd.Timestamp(year=year, month=2, day=15))\n",
    "        ]\n",
    "        \n",
    "        severe_frost = int((year_data['tmin'] <= -4.4).any())\n",
    "        \n",
    "        frost_list.append({\n",
    "            'year': year,\n",
    "            'severe_frost': severe_frost\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(frost_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d7d46",
   "metadata": {},
   "source": [
    "### Base Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529945d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chill_df = calculate_chill_hours(full_temps_dc)\n",
    "cum_gdd_df = calculate_cumulative_gdd(full_temps_dc)\n",
    "frost_df = calculate_severe_frost(full_temps_dc)\n",
    "\n",
    "base_df = (\n",
    "    cherry_dc\n",
    "    .merge(chill_df, on='year')\n",
    "    .merge(cum_gdd_df, on='year')\n",
    "    .merge(frost_df, on='year')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f309d94",
   "metadata": {},
   "source": [
    "Biologcial machanism is working because gdd is negatively correlated with bloom_doy, and chill_hours has weak, positive correlation with bloom_doy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6326aa91",
   "metadata": {},
   "source": [
    "## Optimizing GDD Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58036e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base 3°C → Bloom DOY RMSE: 5.09\n",
      "Base 4°C → Bloom DOY RMSE: 5.05\n",
      "Base 4.5°C → Bloom DOY RMSE: 5.10\n",
      "Base 5°C → Bloom DOY RMSE: 5.08\n",
      "Base 6°C → Bloom DOY RMSE: 5.38\n",
      "Base 7°C → Bloom DOY RMSE: 5.60\n",
      "\n",
      "Best base temperature:\n",
      "4°C (RMSE = 5.05 days)\n"
     ]
    }
   ],
   "source": [
    "candidate_thresholds = [3, 4, 4.5, 5, 6, 7]\n",
    "\n",
    "best_thresh = None\n",
    "best_rmse = np.inf\n",
    "\n",
    "results = []\n",
    "\n",
    "for thresh in candidate_thresholds:\n",
    "\n",
    "    # Compute historical GDD at bloom\n",
    "    def calc_gdd(year, bloom_doy):\n",
    "        gdd_data = full_temps_dc[\n",
    "            (full_temps_dc['year'] == year) &\n",
    "            (full_temps_dc['doy'] <= bloom_doy)\n",
    "        ]\n",
    "        return np.sum(np.maximum(gdd_data['tavg'] - thresh, 0))\n",
    "\n",
    "    temp_df = base_df.copy()\n",
    "    temp_df['gdd'] = temp_df.apply(\n",
    "        lambda r: calc_gdd(r['year'], r['bloom_doy']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Fit chill → required GDD model\n",
    "    X = temp_df[['chill_hours']]\n",
    "    y = temp_df['gdd']\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    # Predict bloom DOY historically using threshold simulation \n",
    "    predicted_doys = []\n",
    "\n",
    "    for _, row in temp_df.iterrows():\n",
    "\n",
    "        year = row['year']\n",
    "        chill = row['chill_hours']\n",
    "\n",
    "        required_gdd = reg.predict([[chill]])[0]\n",
    "\n",
    "        year_temps = full_temps_dc[\n",
    "            full_temps_dc['year'] == year\n",
    "        ].copy()\n",
    "\n",
    "        year_temps['gdd'] = np.maximum(\n",
    "            year_temps['tavg'] - thresh, 0\n",
    "        )\n",
    "        year_temps['cum_gdd'] = year_temps['gdd'].cumsum()\n",
    "\n",
    "        pred_doy = year_temps.loc[\n",
    "            year_temps['cum_gdd'] >= required_gdd\n",
    "        ]['doy'].iloc[0]\n",
    "\n",
    "        predicted_doys.append(pred_doy)\n",
    "\n",
    "    # Evaluate DOY accuracy\n",
    "    rmse = np.sqrt(\n",
    "        mean_squared_error(temp_df['bloom_doy'], predicted_doys)\n",
    "    )\n",
    "\n",
    "    results.append((thresh, rmse))\n",
    "    print(f\"Base {thresh}°C → Bloom DOY RMSE: {rmse:.2f}\")\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_thresh = thresh\n",
    "\n",
    "\n",
    "print(\"\\nBest base temperature:\")\n",
    "print(f\"{best_thresh}°C (RMSE = {best_rmse:.2f} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260afc5f",
   "metadata": {},
   "source": [
    "Since 4°C was deemed the most optimal threshold, which is close to what the literature says is typical for Yoshino trees at 5°C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14d610",
   "metadata": {},
   "source": [
    "# Cumulative GDD Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254566c",
   "metadata": {},
   "source": [
    "## Model 1 - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ac17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.3913719783919145\n",
      "Coefficients: {'chill_hours': 0.36230701385770164, 'cumulative_gdd': 0.0006243537025314793}\n"
     ]
    }
   ],
   "source": [
    "model_linear = base_df.copy()\n",
    "\n",
    "features = ['chill_hours', 'cumulative_gdd']\n",
    "X = model_linear[features]\n",
    "y = model_linear['bloom_doy']\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X, y)\n",
    "\n",
    "preds = lin_model.predict(X)\n",
    "\n",
    "print(\"R2:\", r2_score(y, preds))\n",
    "print(\"Coefficients:\", dict(zip(features, lin_model.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e23377",
   "metadata": {},
   "source": [
    "* year: -0.87, blooming trends slightly earlier over time\n",
    "    * Warming signal\n",
    "* chill hours: 0.0057, more chill forces later bloom \n",
    "    * counterintuitive\n",
    "* gdd: -0.0033, more gdd the earlier the bloom\n",
    "    * biologially correct\n",
    "\n",
    "Linear model is strugling to capture the uniquenss of the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff856c",
   "metadata": {},
   "source": [
    "## Model 2 - Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12f8c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial R2: 0.39549437059224335\n"
     ]
    }
   ],
   "source": [
    "model_poly = base_df.copy()\n",
    "\n",
    "features = ['chill_hours', 'cumulative_gdd']\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(model_poly[features])\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly, y)\n",
    "\n",
    "preds_poly = poly_model.predict(X_poly)\n",
    "\n",
    "print(\"Polynomial R2:\", r2_score(y, preds_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4080b4",
   "metadata": {},
   "source": [
    "Nonlinear adds almost nothing to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7fb0f4",
   "metadata": {},
   "source": [
    "### Model 3 - Linear with Frost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174f0ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frost R2: 0.3914645197241955\n"
     ]
    }
   ],
   "source": [
    "model_frost = base_df.copy()\n",
    "\n",
    "features = ['chill_hours', 'cumulative_gdd', 'severe_frost']\n",
    "\n",
    "X = model_frost[features]\n",
    "y = model_frost['bloom_doy']\n",
    "\n",
    "frost_model = LinearRegression()\n",
    "frost_model.fit(X, y)\n",
    "\n",
    "print(\"Frost R2:\", r2_score(y, frost_model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1e2e8",
   "metadata": {},
   "source": [
    "## 2026 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0f9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chill_2026 = calculate_chill_hours(temps_2026_dc)\n",
    "gdd_2026 = calculate_cumulative_gdd(temps_2026_dc)\n",
    "frost_2026 = calculate_severe_frost(temps_2026_dc)\n",
    "\n",
    "df_2026 = (\n",
    "    chill_2026\n",
    "    .merge(gdd_2026, on='year')\n",
    "    .merge(frost_2026, on='year')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed13bd79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- severe_frost\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     10\u001b[0m features_poly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(poly\u001b[38;5;241m.\u001b[39mfeature_names_in_)\n\u001b[0;32m---> 11\u001b[0m bloom_2026 \u001b[38;5;241m=\u001b[39m predict_year(poly_model, df_2026\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]), features, poly\u001b[38;5;241m=\u001b[39mpoly)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Bloom DOY 2026:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bloom_2026)\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mpredict_year\u001b[0;34m(model, df, feature_cols, poly)\u001b[0m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m df[feature_cols]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m poly \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     X \u001b[38;5;241m=\u001b[39m poly\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:432\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform data to polynomial features.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    `csr_matrix`.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    433\u001b[0m     X, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    434\u001b[0m )\n\u001b[1;32m    436\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    437\u001b[0m max_int32 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- severe_frost\n"
     ]
    }
   ],
   "source": [
    "def predict_year(model, df, feature_cols, poly=None):\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    \n",
    "    if poly is not None:\n",
    "        X = poly.transform(X)\n",
    "    \n",
    "    return model.predict(X)\n",
    "\n",
    "features_poly = list(poly.feature_names_in_)\n",
    "bloom_2026 = predict_year(poly_model, df_2026.drop(columns=['year']), features, poly=poly)\n",
    "print(\"Predicted Bloom DOY 2026:\", bloom_2026)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a99b9c",
   "metadata": {},
   "source": [
    "### Comparison of 2026 Prediction to Historical Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_bloom = base_df['bloom_doy']\n",
    "\n",
    "plt.hist(historical_bloom, bins=15, color='skyblue', edgecolor='black')\n",
    "plt.axvline(105, color='red', linestyle='--', label='Predicted 2026')\n",
    "plt.title(\"Historical Peak Bloom DOY Distribution (Washington, DC)\")\n",
    "plt.xlabel(\"Day of Year (DOY)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8541773",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = np.mean(historical_bloom <= 105) * 100\n",
    "print(\"2026 prediction percentile:\", percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d08e034",
   "metadata": {},
   "source": [
    "## Modeling Change: GDD Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64ee81",
   "metadata": {},
   "source": [
    "Initial modeling with GDD was using cumulative GDD to predict bloom date, but that caused circular modeling, especially when trying to predict future bloom dates. Now GDD is modeled as a threshold:\n",
    "$GDD_{crit} = a + b * Chill$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ce7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_gdd(df, chill_df, chill_threshold=800, base_temp=4.4):\n",
    "    df = df.copy()\n",
    "    df['gdd'] = np.maximum(df['tavg'] - base_temp, 0)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    merged = df.merge(chill_df, on='year')\n",
    "    \n",
    "    threshold_results = []\n",
    "    \n",
    "    for year in merged['year'].unique():\n",
    "        year_data = merged[merged['year'] == year]\n",
    "        \n",
    "        if year_data['chill_hours'].iloc[0] >= chill_threshold:\n",
    "            gdd_total = year_data['gdd'].sum()\n",
    "        else:\n",
    "            gdd_total = 0\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'year': year,\n",
    "            'threshold_gdd': gdd_total\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(threshold_results)\n",
    "\n",
    "threshold_gdd_df = calculate_threshold_gdd(\n",
    "    full_temps_dc,\n",
    "    chill_df,\n",
    "    chill_threshold=800,\n",
    "    base_temp=4.4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe8281",
   "metadata": {},
   "source": [
    "### Model 1 - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f32b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_threshold = (\n",
    "    base_df[['year', 'bloom_doy', 'chill_hours']]  # keep what you want\n",
    "    .merge(threshold_gdd_df, on='year')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['chill_hours', 'threshold_gdd']\n",
    "\n",
    "X = model_threshold[features]\n",
    "y = model_threshold['bloom_doy']\n",
    "\n",
    "threshold_model = LinearRegression()\n",
    "threshold_model.fit(X, y)\n",
    "\n",
    "preds = threshold_model.predict(X)\n",
    "\n",
    "print(\"Threshold Model R2:\", r2_score(y, preds))\n",
    "print(\"Coefficients:\", dict(zip(features, threshold_model.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b1ab2",
   "metadata": {},
   "source": [
    "#### Threshold-Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceff2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['threshold_gdd']\n",
    "\n",
    "X = model_threshold[features]\n",
    "y = model_threshold['bloom_doy']\n",
    "\n",
    "threshold_only_model = LinearRegression()\n",
    "threshold_only_model.fit(X, y)\n",
    "\n",
    "print(\"Threshold Only R2:\",\n",
    "      r2_score(y, threshold_only_model.predict(X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
